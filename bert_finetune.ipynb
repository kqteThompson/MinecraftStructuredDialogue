{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505b0e3f-f343-4d80-b629-37db793eb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73e6c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f46b71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c899cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for GPU\n",
    "torch.cuda.is_available()\n",
    "# device = torch.device('cuda')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdea08a4-3441-4461-a77c-326dee410805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153bb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_relations = {'Comment':0, 'Contrast':1, 'Correction':2, 'Question-answer_pair':3, 'Acknowledgement':4,'Elaboration':5,\n",
    "                 'Clarification_question':6, 'Conditional':7, 'Continuation':8, 'Result':9, 'Explanation':10, 'Q-Elab':11,\n",
    "                 'Alternation':12, 'Narration':13, 'Confirmation_question':14, 'Sequence':15, 'Break':16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd422b6-eae8-4d65-87fe-12fcde1d5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "home=%pwd\n",
    "filename = home + '/data/TRAIN_407.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71de8c0",
   "metadata": {},
   "source": [
    "load and preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3ccf1f-b088-429b-945b-80c36c24de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, input_format, position_ids_compute, tokenize\n",
    "from bert_format import undersample, format_time, flat_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ca18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: /home/kate/LREC/data/TRAIN_407.json\n",
      "407 dialogs, 21822 edus, 26299 relations, 194 backward relations\n",
      "4787 edus have multiple parents\n"
     ]
    }
   ],
   "source": [
    "data = load_data(filename, map_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "863b6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split out a certain portion of validation data (a function of length?)\n",
    "train_data = data[40:]\n",
    "valid_data = data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d527f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22781 relations\n",
      "126994 candidates\n",
      "104213 non attached\n"
     ]
    }
   ],
   "source": [
    "input_text_train, labels_complete_train, raw_train = input_format(train_data, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd9191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2554 relations\n",
      "14364 candidates\n",
      "11810 non attached\n"
     ]
    }
   ],
   "source": [
    "input_text_val, labels_complete_val, raw_val = input_format(valid_data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "132dab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer and token ids\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b30dc5a1-da79-4213-98dd-7c188a981f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "put = ['1','0']\n",
    "colors = ['r', 'b', 'g', 'o', 'y', 'p']\n",
    "listx = ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n']\n",
    "listy = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "listz = ['a', 'e', 'i', 'o', 'u', 'p', 'q', 'r', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15fd8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tokens = [''.join([s, t, i, j, k]) for s in put\n",
    "                for t in colors\n",
    "                for i in listx\n",
    "                for j in listy\n",
    "                for k in listz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05d69a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13068"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(coord_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50509876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2482706",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "481e394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train, attention_masks_train, token_type_ids_train = tokenize(input_text_train, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d062dbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126994"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c255d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_val, attention_masks_val, token_type_ids_val = tokenize(input_text_val, tokenizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaaa118",
   "metadata": {},
   "source": [
    "Compute position ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acc31244-405f-4a50-aee8-bda30f991cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_train = position_ids_compute(tokenizer, input_ids_train, raw_train, labels_complete_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59f8b622-400d-4a7e-b209-15b2cec47bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_val = position_ids_compute(tokenizer, input_ids_val, raw_val, labels_complete_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "894e22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_train = torch.tensor(position_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b929b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_val = torch.tensor(position_ids_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9c4df",
   "metadata": {},
   "source": [
    "Undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d049058",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = [l[3] for l in labels_complete_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88f0b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = [l[3] for l in labels_complete_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "743e18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(labels_train)\n",
    "labels_val = torch.tensor(labels_val)\n",
    "labels_complete_train = torch.tensor(labels_complete_train)\n",
    "labels_complete_val = torch.tensor(labels_complete_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "565fcb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB need to choose a drop number\n",
    "labels_complete_train, labels_train, input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train = undersample(68576, labels_complete_train, labels_train, input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f059a9b",
   "metadata": {},
   "source": [
    "Load data loader and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a12e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "defcf37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5500be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, token_type_ids_val, position_ids_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0436fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ebf096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96e97831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = True, attention_probs_dropout_prob=0, hidden_dropout_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66c1391e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(42064, 768)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!!important -- must add new token embeddings to BERT\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b960960f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42064, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f98e5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kate/miniconda3/envs/bert_env/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1.5e-5,\n",
    "                  eps = 1e-8\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0ccb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(train_dataloader) * 2\n",
    "seed_val = 18\n",
    "total_t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df5625",
   "metadata": {},
   "source": [
    "Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3718ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = home + '/models/'\n",
    "bert_name = 'finetune_d7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12cb4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "  Batch   500  of  2,855.    Elapsed: 0:01:24.\n",
      "  Batch 1,000  of  2,855.    Elapsed: 0:02:50.\n",
      "  Batch 1,500  of  2,855.    Elapsed: 0:04:13.\n",
      "  Batch 2,000  of  2,855.    Elapsed: 0:05:36.\n",
      "  Batch 2,500  of  2,855.    Elapsed: 0:06:58.\n",
      "  Training Loss:  0.23582668830877115\n",
      "  Training took:  0:08:00\n",
      "Running Validation\n",
      "  Accuracy:  0.9350342029907732\n",
      "  Validation Loss:  0.18419285180391473\n",
      "  Validation took:  0:00:20\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "  Batch   500  of  2,855.    Elapsed: 0:01:26.\n",
      "  Batch 1,000  of  2,855.    Elapsed: 0:02:53.\n",
      "  Batch 1,500  of  2,855.    Elapsed: 0:04:19.\n",
      "  Batch 2,000  of  2,855.    Elapsed: 0:05:46.\n",
      "  Batch 2,500  of  2,855.    Elapsed: 0:07:11.\n",
      "  Training Loss:  0.18037610872927565\n",
      "  Training took:  0:08:12\n",
      "Running Validation\n",
      "  Accuracy:  0.9323098950047725\n",
      "  Validation Loss:  0.18006433696301452\n",
      "  Validation took:  0:00:19\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(2):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, 2))\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        result = model(batch[0].to(device),\n",
    "                       token_type_ids=batch[2].to(device),\n",
    "                       attention_mask=batch[1].to(device),\n",
    "                       position_ids = batch[3].to(device),\n",
    "                       labels=batch[4].to(device),\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Training Loss: \",avg_train_loss)\n",
    "    print(\"  Training took: \", training_time)\n",
    "    print(\"Running Validation\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Evaluation step\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            result = model(batch[0].to(device),\n",
    "                           token_type_ids=batch[2].to(device),\n",
    "                           attention_mask=batch[1].to(device),\n",
    "                           position_ids = batch[3].to(device),\n",
    "                           labels=batch[4].to(device),\n",
    "                           return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = batch[4].to(device).cpu().numpy()\n",
    "        # if device == 'cuda' :\n",
    "        #     # logits = logits.detach().cpu().numpy()\n",
    "        #     logits = logits.detach().cpu().numpy()\n",
    "        #     label_ids = batch[4].to(device).cpu().numpy()\n",
    "        #     # label_ids = batch[4].to(device).to('cpu').numpy()\n",
    "        #     # Move logits and labels to CPU\n",
    "        # else : label_ids = batch[4].to(device)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        #print(label_ids)\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: \", avg_val_accuracy)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: \", avg_val_loss)\n",
    "    print(\"  Validation took: \",validation_time)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}, model_path + bert_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078e0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db17e40",
   "metadata": {},
   "source": [
    "Get scores on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcd1b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "# filename = home + '/data/DEV_32_bert.json'\n",
    "filename = home + '/data/TEST_102_bert.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "965e4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: /home/kate/LREC/data/TEST_102_bert.json\n",
      "102 dialogs, 5032 edus, 6041 relations, 56 backward relations\n",
      "1081 edus have multiple parents\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data(filename, map_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "191ffd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886 relations\n",
      "44710 candidates\n",
      "38824 non attached\n"
     ]
    }
   ],
   "source": [
    "input_text_test, labels_complete_test, raw_test = input_format(test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cec31cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test, attention_masks_test, token_type_ids_test = tokenize(input_text_test, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "088da1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_test = position_ids_compute(tokenizer, input_ids_test, raw_test, labels_complete_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28dfe326",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_test = torch.tensor(position_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f29349aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = [l[3] for l in labels_complete_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e725685",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = torch.tensor(labels_test)\n",
    "labels_complete_test = torch.tensor(labels_complete_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f45bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, token_type_ids_test, position_ids_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5344268",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44ecfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = home + '/models/finetune_d10.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e48042df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embedder = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = True, attention_probs_dropout_prob=0, hidden_dropout_prob=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "240aeb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(42064, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11fe859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42064, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "embedder.load_state_dict(checkpoint['model_state_dict'])\n",
    "embedder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "888a002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f5bf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 44,710 test cands...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test cands...'.format(len(input_ids_test)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict\n",
    "for batch in test_dataloader:\n",
    "  # # Add batch to GPU\n",
    "  # batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # # Unpack the inputs from our dataloader\n",
    "  # b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # # Telling the model not to compute or store gradients, saving memory and\n",
    "  # # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(batch[0].to(device),\n",
    "                      token_type_ids=batch[2].to(device),\n",
    "                      attention_mask=batch[1].to(device),\n",
    "                      position_ids = batch[3].to(device),\n",
    "                      labels=batch[4].to(device),\n",
    "                      return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  # logits = logits.detach().cpu().numpy()\n",
    "  # label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = batch[4].to(device).cpu().numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84d481e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c63679f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c364bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results across all batches.\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af45736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9d7c1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.858414079493771, 0.737512742099898, 0.7933838983825277, None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(flat_true_labels, flat_predictions, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4dde8",
   "metadata": {},
   "source": [
    "save output <br>\n",
    "list of lists with [dialogue index, x index, y index, true attach, true label, predicted attach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4d8c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels = labels_complete_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15c5213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 1, 0],\n",
       " [0, 0, 2, 1, 8],\n",
       " [0, 1, 2, 0, -1],\n",
       " [0, 0, 3, 0, -1],\n",
       " [0, 1, 3, 0, -1],\n",
       " [0, 2, 3, 1, 5],\n",
       " [0, 0, 4, 0, -1],\n",
       " [0, 1, 4, 0, -1],\n",
       " [0, 2, 4, 0, -1],\n",
       " [0, 3, 4, 1, 9]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7703b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_stats = []\n",
    "for i, lab in enumerate(full_labels):\n",
    "    li = []\n",
    "    li += lab\n",
    "    li.append(flat_predictions[i])\n",
    "    save_stats.append(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c078d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pickle-mixin\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ed773a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home + '/pickles/' + 'scores_finetune_d10_test.pkl', 'wb') as f:\n",
    "    pickle.dump(save_stats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
