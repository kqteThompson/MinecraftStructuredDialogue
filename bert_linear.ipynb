{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for GPU\n",
    "torch.cuda.is_available()\n",
    "# device = torch.device('cuda')\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_relations = {'Comment':0, 'Contrast':1, 'Correction':2, 'Question-answer_pair':3, 'Acknowledgement':4,'Elaboration':5,\n",
    "                 'Clarification_question':6, 'Conditional':7, 'Continuation':8, 'Result':9, 'Explanation':10, 'Q-Elab':11,\n",
    "                 'Alternation':12, 'Narration':13, 'Confirmation_question':14, 'Sequence':15, 'Break':16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home=%pwd\n",
    "filename = home + '/data/TRAIN_407.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, input_format, position_ids_compute, tokenize\n",
    "from bert_format import undersample, format_time, flat_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: /home/kate/LREC/data/TRAIN_407.json\n",
      "407 dialogs, 21822 edus, 26299 relations, 194 backward relations\n",
      "4787 edus have multiple parents\n"
     ]
    }
   ],
   "source": [
    "data = load_data(filename, map_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split out a certain portion of validation data (a function of length?)\n",
    "train_data = data[40:]\n",
    "valid_data = data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23122 relations\n",
      "175919 candidates\n",
      "152797 non attached\n"
     ]
    }
   ],
   "source": [
    "input_text_train, labels_train, raw_train = input_format(train_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592 relations\n",
      "19920 candidates\n",
      "17328 non attached\n"
     ]
    }
   ],
   "source": [
    "input_text_valid, labels_valid, raw_valid = input_format(valid_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer and token ids\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "put = ['1','0']\n",
    "colors = ['r', 'b', 'g', 'o', 'y', 'p']\n",
    "listx = ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n']\n",
    "listy = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
    "listz = ['a', 'e', 'i', 'o', 'u', 'p', 'q', 'r', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_tokens = [''.join([s, t, i, j, k]) for s in put\n",
    "                for t in colors\n",
    "                for i in listx\n",
    "                for j in listy\n",
    "                for k in listz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13068"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens(coord_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42064"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train, attention_masks_train, token_type_ids_train = tokenize(input_text_train, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_valid, attention_masks_valid, token_type_ids_valid = tokenize(input_text_valid, tokenizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute position ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_train = position_ids_compute(tokenizer, input_ids_train, raw_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_valid = position_ids_compute(tokenizer, input_ids_valid, raw_valid, labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_train = torch.tensor(position_ids_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_valid = torch.tensor(position_ids_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersample <br>\n",
    "For Bertlinear we use the undersample function because..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_format import undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175919\n",
      "152797\n",
      "23122\n"
     ]
    }
   ],
   "source": [
    "#all cands\n",
    "print(len(labels_train))\n",
    "#unattached cands\n",
    "print(sum([1 for i in labels_train if i[3] == 0]))\n",
    "#attached cands\n",
    "print(sum([1 for i in labels_train if i[3] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_attach_train = [l[3] for l in labels_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_attach_valid = [l[3] for l in labels_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = torch.tensor(labels_train)\n",
    "labels_valid = torch.tensor(labels_valid)\n",
    "labels_attach_train = torch.tensor(labels_attach_train)\n",
    "labels_attach_valid = torch.tensor(labels_attach_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train, labels_attach_train, input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train = undersample(68576, labels_train, labels_attach_train, input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gather metadata from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make meta data -- lists of distances -- ADD INFO FOR RESULT\n",
    "meta_data_train = []\n",
    "for i in range(len(labels_train)):\n",
    "  lbs = labels_train[i].tolist()\n",
    "  # meta_data_train.append([lbs[2], lbs[2]-lbs[1], lbs[5]])\n",
    "  # meta_data_train.append([lbs[2], lbs[2]-lbs[1], lbs[5], lbs[6]])\n",
    "  meta_data_train.append([lbs[2], lbs[2]-lbs[1]])\n",
    "\n",
    "meta_data_valid = []\n",
    "for i in range(len(labels_valid)):\n",
    "  lbs = labels_valid[i].tolist()\n",
    "  # meta_data_valid.append([lbs[2], lbs[2]-lbs[1], lbs[5]])\n",
    "  # meta_data_valid.append([lbs[2], lbs[2]-lbs[1], lbs[5], lbs[6]])\n",
    "  meta_data_valid.append([lbs[2], lbs[2]-lbs[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create metadata batches\n",
    "def get_batches(len_data, batch_size):\n",
    "    indices = [i for i in range(len_data)]\n",
    "    batches = []\n",
    "    for i in range(len_data // batch_size + bool(len_data) % batch_size):\n",
    "        batches.append(indices[i * batch_size:(i + 1) * batch_size])\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = get_batches(len(meta_data_train), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batches = get_batches(len(meta_data_valid), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_batches = []\n",
    "for ba in train_batches:\n",
    "  meta_train_batches.append([meta_data_train[b] for b in ba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_valid_batches = []\n",
    "for ba in valid_batches:\n",
    "  meta_valid_batches.append([meta_data_valid[b] for b in ba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, token_type_ids_train, position_ids_train, labels_attach_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([91698, 113]),\n",
       " torch.Size([91698, 113]),\n",
       " torch.Size([91698, 113]),\n",
       " torch.Size([91698]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train.size(), attention_masks_train.size(), position_ids_train.size(), labels_attach_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19920, 71]),\n",
       " torch.Size([19920, 71]),\n",
       " torch.Size([19920, 71]),\n",
       " torch.Size([19920]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_valid.size(), attention_masks_valid.size(), position_ids_valid.size(), labels_attach_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(input_ids_valid, attention_masks_valid, token_type_ids_valid, position_ids_valid, labels_attach_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = SequentialSampler(train_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load finetuned from first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = home + '/models/finetune_d10.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embedder = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = True, attention_probs_dropout_prob=0, hidden_dropout_prob=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(42064, 768)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!!resize embedder to account for new embeddings!\n",
    "embedder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42064, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "embedder.load_state_dict(checkpoint['model_state_dict'])\n",
    "embedder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix neural net here\n",
    "#hidden_size = 774\n",
    "#hidden_size = 772 for just incoming rels\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            # nn.Linear(params.hidden_size, params.hidden_size_1),\n",
    "            nn.Linear(770, 2000),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(2000, 1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.train()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(params=linear.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_path = home + '/models/'\n",
    "save_linear_name =  'linear_d10_pass1.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "batch no  0\n",
      "epoch  0\n",
      "batch no  2865\n",
      "avg train loss:  0.12048575012318774\n",
      "going to eval\n",
      "avg val loss:  0.17581124330237718\n",
      "--------------------------------------\n",
      "epoch  1\n",
      "batch no  0\n",
      "epoch  1\n",
      "batch no  2865\n",
      "avg train loss:  0.11419450670814782\n",
      "going to eval\n",
      "avg val loss:  0.17970858346525112\n",
      "--------------------------------------\n",
      "epoch  2\n",
      "batch no  0\n",
      "epoch  2\n",
      "batch no  2865\n",
      "avg train loss:  0.1126828385401317\n",
      "going to eval\n",
      "avg val loss:  0.18190164687300706\n",
      "--------------------------------------\n",
      "epoch  3\n",
      "batch no  0\n",
      "epoch  3\n",
      "batch no  2865\n",
      "avg train loss:  0.11136398847693862\n",
      "going to eval\n",
      "avg val loss:  0.18053217681678294\n",
      "--------------------------------------\n",
      "epoch  4\n",
      "batch no  0\n",
      "epoch  4\n",
      "batch no  2865\n",
      "avg train loss:  0.11054066676408929\n",
      "going to eval\n",
      "avg val loss:  0.1840287333616522\n",
      "--------------------------------------\n",
      "epoch  5\n",
      "batch no  0\n",
      "epoch  5\n",
      "batch no  2865\n",
      "avg train loss:  0.10965474318961216\n",
      "going to eval\n",
      "avg val loss:  0.18483605031368813\n",
      "--------------------------------------\n",
      "epoch  6\n",
      "batch no  0\n",
      "epoch  6\n",
      "batch no  2865\n",
      "avg train loss:  0.10868686022752323\n",
      "going to eval\n",
      "avg val loss:  0.18283633011345413\n",
      "--------------------------------------\n",
      "epoch  7\n",
      "batch no  0\n",
      "epoch  7\n",
      "batch no  2865\n",
      "avg train loss:  0.10879020653330361\n",
      "going to eval\n",
      "avg val loss:  0.18656501252931823\n",
      "--------------------------------------\n",
      "epoch  8\n",
      "batch no  0\n",
      "epoch  8\n",
      "batch no  2865\n",
      "avg train loss:  0.1087276608098574\n",
      "going to eval\n",
      "avg val loss:  0.18323999293369764\n",
      "--------------------------------------\n",
      "epoch  9\n",
      "batch no  0\n",
      "epoch  9\n",
      "batch no  2865\n",
      "avg train loss:  0.1073497182529404\n",
      "going to eval\n",
      "avg val loss:  0.1831800254313335\n",
      "--------------------------------------\n",
      "epoch  10\n",
      "batch no  0\n",
      "epoch  10\n",
      "batch no  2865\n",
      "avg train loss:  0.10708216570814277\n",
      "going to eval\n",
      "avg val loss:  0.182815179711355\n",
      "--------------------------------------\n",
      "epoch  11\n",
      "batch no  0\n",
      "epoch  11\n",
      "batch no  2865\n",
      "avg train loss:  0.10652373533969549\n",
      "going to eval\n",
      "avg val loss:  0.18419526239536047\n",
      "--------------------------------------\n",
      "epoch  12\n",
      "batch no  0\n",
      "epoch  12\n",
      "batch no  2865\n",
      "avg train loss:  0.10591341750725547\n",
      "going to eval\n",
      "avg val loss:  0.1845407529728843\n",
      "--------------------------------------\n",
      "epoch  13\n",
      "batch no  0\n",
      "epoch  13\n",
      "batch no  2865\n",
      "avg train loss:  0.10534463637836332\n",
      "going to eval\n",
      "avg val loss:  0.18562070358935878\n",
      "--------------------------------------\n",
      "epoch  14\n",
      "batch no  0\n",
      "epoch  14\n",
      "batch no  2865\n",
      "avg train loss:  0.10523764527612739\n",
      "going to eval\n",
      "avg val loss:  0.18412000831187797\n",
      "--------------------------------------\n",
      "finished_training, saving to :  /home/kate/LREC/models/linear_d10_pass1.pth\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    loss_sum_train = 0\n",
    "    linear.train()\n",
    "    for e, batch in enumerate(train_dataloader):\n",
    "      if e in [0, len(train_dataloader)-1]:\n",
    "        print(\"epoch \", epoch)\n",
    "        print(\"batch no \", e)\n",
    "      output = embedder(batch[0].to(device),\n",
    "                        token_type_ids = batch[2].to(device),\n",
    "                        attention_mask = batch[1].to(device),\n",
    "                        position_ids = batch[3].to(device),\n",
    "                        labels = batch[4].to(device),\n",
    "                        return_dict=True)\n",
    "      #concat each candidate embedding with metadata tensor\n",
    "      #stack these\n",
    "      H_embed = torch.stack([torch.cat((r[0], torch.tensor(meta_train_batches[e][i]).to(device)),0) for i, r in enumerate(output.hidden_states[-1])])\n",
    "      H_embed = H_embed.to(device)\n",
    "      logits = linear(H_embed).unsqueeze(0)\n",
    "      logits = logits.squeeze(-1)\n",
    "\n",
    "      #print(batch[4])\n",
    "\n",
    "      target = torch.tensor([[float(b) for b in batch[4]]]).to(device)\n",
    "      #target = float(batch[4][None,:]).to(device)\n",
    "      #target = torch.tensor([[float(lab[3]) for lab in labels[i]]]).to(device)\n",
    "      #need to detach?\n",
    "      # print(target.size())\n",
    "      # print(logits.size())\n",
    "\n",
    "      loss = criterion(input=logits, target=target)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      loss_sum_train += loss.item()\n",
    "\n",
    "    # Calculate the average train loss over all of the batches.\n",
    "    avg_train_loss = loss_sum_train / len(train_dataloader)\n",
    "    print(\"avg train loss: \", avg_train_loss)\n",
    "\n",
    "\n",
    "    print(\"going to eval\")\n",
    "    linear.eval()\n",
    "    loss_sum_valid = 0\n",
    "\n",
    "    for e, batch in enumerate(validation_dataloader):\n",
    "      with torch.no_grad():\n",
    "        output = embedder(batch[0].to(device),\n",
    "                        token_type_ids = batch[2].to(device),\n",
    "                        attention_mask = batch[1].to(device),\n",
    "                        position_ids = batch[3].to(device),\n",
    "                        labels = batch[4].to(device),\n",
    "                        return_dict=True)\n",
    "\n",
    "      H_embed = torch.stack([torch.cat((r[0], torch.tensor(meta_valid_batches[e][i]).to(device)),0) for i, r in enumerate(output.hidden_states[-1])])\n",
    "      H_embed = H_embed.to(device)\n",
    "      with torch.no_grad():\n",
    "            logits = linear(H_embed).unsqueeze(0)\n",
    "\n",
    "      logits = logits.squeeze(-1)\n",
    "\n",
    "      target = torch.tensor([[float(b) for b in batch[4]]]).to(device)\n",
    "      # target = batch[4].to(device)\n",
    "\n",
    "      loss = criterion(input=logits, target=target)\n",
    "\n",
    "      loss_sum_valid += loss.item()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = loss_sum_valid / len(validation_dataloader)\n",
    "    print(\"avg val loss: \", avg_val_loss)\n",
    "\n",
    "    print('--------------------------------------')\n",
    "\n",
    "output_model = linear_model_path + save_linear_name\n",
    "\n",
    "print('finished_training, saving to : ', output_model)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': linear.state_dict(),\n",
    "}, output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get scores on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: /home/kate/LREC/data/TEST_102_bert.json\n",
      "102 dialogs, 5032 edus, 6041 relations, 56 backward relations\n",
      "1081 edus have multiple parents\n"
     ]
    }
   ],
   "source": [
    "#load test data\n",
    "# filename = home + '/data/DEV_32_bert.json'\n",
    "filename = home + '/data/TEST_102_bert.json'\n",
    "test_data = load_data(filename, map_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886 relations\n",
      "44710 candidates\n",
      "38824 non attached\n"
     ]
    }
   ],
   "source": [
    "input_text_test, labels_test, raw_test = input_format(test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test, attention_masks_test, token_type_ids_test = tokenize(input_text_test, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_test = position_ids_compute(tokenizer, input_ids_test, raw_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids_test = torch.tensor(position_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_attach_test = [l[3] for l in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_test = []\n",
    "for i in range(len(labels_test)):\n",
    "  lbs = labels_test[i]\n",
    "  # meta_data_test.append([lbs[2], lbs[2]-lbs[1], lbs[5]])\n",
    "  # meta_data_test.append([lbs[2], lbs[2]-lbs[1], lbs[5], lbs[6]])\n",
    "  meta_data_test.append([lbs[2], lbs[2]-lbs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = get_batches(len(meta_data_test), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_batches = []\n",
    "for ba in test_batches:\n",
    "  meta_test_batches.append([meta_data_test[b] for b in ba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_batches = []\n",
    "for ba in test_batches:\n",
    "  labels_test_batches.append([labels_test[b] for b in ba])\n",
    "# labels_test_batches = []\n",
    "# for ba in test_batches:\n",
    "#   labels_test_batches.append([labels_test[b] for b in ba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, token_type_ids_test, position_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = 32\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(if need to reload models...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=770, out_features=2000, bias=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=2000, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = home + '/models/' +  'linear_d10_pass1.pth'\n",
    "linear = NeuralNetwork().to(device)\n",
    "checkpoint = torch.load(model_path, map_location='cuda')\n",
    "linear.load_state_dict(checkpoint['model_state_dict'])\n",
    "linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "linear.eval()\n",
    "\n",
    "for e, batch in enumerate(test_dataloader):\n",
    "  with torch.no_grad():\n",
    "    output = embedder(batch[0].to(device),\n",
    "                    token_type_ids = batch[2].to(device),\n",
    "                    attention_mask = batch[1].to(device),\n",
    "                    position_ids = batch[3].to(device),\n",
    "                    # labels = batch[4].to(device),\n",
    "                    return_dict=True)\n",
    "\n",
    "  H_embed = torch.stack([torch.cat((r[0], torch.tensor(meta_test_batches[e][i]).to(device)),0) for i, r in enumerate(output.hidden_states[-1])])\n",
    "  H_embed = H_embed.to(device)\n",
    "  with torch.no_grad():\n",
    "        logits = linear(H_embed).unsqueeze(0)\n",
    "\n",
    "  #print(logits)\n",
    "  m = nn.Sigmoid()\n",
    "  mod =(m(logits)).squeeze(-1).cpu().tolist()[0]\n",
    "  #print(mod)\n",
    "  xs = [i for i in range(len(mod)) if mod[i] > 0.81]  # 0.95\n",
    "  #print(xs)\n",
    "  # print(len(xs))\n",
    "  #add highest in batch if nothing is above 81?? why???\n",
    "  # if len(xs) == 0 : xs += [ np.argmax([float(p[0]) for p in logits[0].cpu()])]\n",
    "  # print(xs)\n",
    "\n",
    "  labels = labels_test_batches[e]\n",
    "  for lab in range(len(labels)):\n",
    "    if lab in xs:\n",
    "      labels[lab].append(1)\n",
    "    else:\n",
    "      labels[lab].append(0)\n",
    "\n",
    "  predictions.extend(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44710"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 1, 0, 1], [0, 0, 2, 1, 8, 1], [0, 1, 2, 0, -1, 0]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach_predictions = [i[5] for i in predictions]\n",
    "true_labels = [i[3] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44710, 44710)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attach_predictions), len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8278381416260772, 0.7507645259938838, 0.7874198146828225, None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(true_labels, attach_predictions, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save predictions<br>\n",
    "list of lists with [dialogue index, x index, y index, true attach, true label, predicted attach]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open(home + '/pickles/' + 'scores_linear_d10_test.pkl', 'wb') as f:\n",
    "#     pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change output to a list of lists so it can be fed to multitask <br>\n",
    "needs to be a list of lists, each list a game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(home + '/pickles/' + 'scores_linear_d10_dev.pkl', 'rb') as f:\n",
    "    predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_inputs = []\n",
    "for i in range(32):\n",
    "    inputs = [[e[1], e[2]] for e in predictions if e[0] == i and e[5]==1]\n",
    "    multitask_inputs.append(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multitask_inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(home + '/pickles/' + 'MT_input_d10_DEV.pkl', 'wb') as f:\n",
    "    pickle.dump(multitask_inputs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
